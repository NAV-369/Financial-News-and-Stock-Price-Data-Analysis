{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "                        date stock  \n",
      "0  2020-06-05 10:30:54-04:00     A  \n",
      "1  2020-06-03 10:45:20-04:00     A  \n",
      "2  2020-05-26 04:30:07-04:00     A  \n",
      "3  2020-05-22 12:45:06-04:00     A  \n",
      "4  2020-05-22 11:38:59-04:00     A  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file relative to the current working directory\n",
    "file_path = \"../data/raw_analyst_ratings.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Inspect the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspect and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "                        date stock  \n",
      "0  2020-06-05 10:30:54-04:00     A  \n",
      "1  2020-06-03 10:45:20-04:00     A  \n",
      "2  2020-05-26 04:30:07-04:00     A  \n",
      "3  2020-05-22 12:45:06-04:00     A  \n",
      "4  2020-05-22 11:38:59-04:00     A  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1407328 entries, 0 to 1407327\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   Unnamed: 0  1407328 non-null  int64 \n",
      " 1   headline    1407328 non-null  object\n",
      " 2   url         1407328 non-null  object\n",
      " 3   publisher   1407328 non-null  object\n",
      " 4   date        1407328 non-null  object\n",
      " 5   stock       1407328 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 64.4+ MB\n",
      "None\n",
      "Unnamed: 0    0\n",
      "headline      0\n",
      "url           0\n",
      "publisher     0\n",
      "date          0\n",
      "stock         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the first few rows\n",
    "print(data.head())\n",
    "\n",
    "# Check the column names and data types\n",
    "print(data.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Normalize Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the column names\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by date (optional but useful for alignment)\n",
    "data = data.sort_values('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Unnamed: 0                                           headline  \\\n",
      "879310       883755                       How Treasuries and ETFs Work   \n",
      "519806       522587      Update on the Luxury Sector: 2nd Quarter 2009   \n",
      "1390006     1396488      Update on the Luxury Sector: 2nd Quarter 2009   \n",
      "1432           1834                             Going Against the Herd   \n",
      "67712         68387  Charles Sizemore Radio Interview Saturday Morning   \n",
      "\n",
      "                                                       url  \\\n",
      "879310   https://www.benzinga.com/28044/how-treasuries-...   \n",
      "519806   https://www.benzinga.com/charles-lewis-sizemor...   \n",
      "1390006  https://www.benzinga.com/charles-lewis-sizemor...   \n",
      "1432     https://www.benzinga.com/charles-lewis-sizemor...   \n",
      "67712    https://www.benzinga.com/11218/charles-sizemor...   \n",
      "\n",
      "                          publisher                      date stock  \n",
      "879310                 Paco Ahlgren 2009-02-14 00:00:00+00:00   NAV  \n",
      "519806   Charles Lewis Sizemore CFA 2009-04-27 00:00:00+00:00    FT  \n",
      "1390006  Charles Lewis Sizemore CFA 2009-04-27 00:00:00+00:00     Y  \n",
      "1432     Charles Lewis Sizemore CFA 2009-04-29 00:00:00+00:00     A  \n",
      "67712    Charles Lewis Sizemore CFA 2009-05-22 00:00:00+00:00    AM  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'date' column to datetime format, handling any errors by coercing them\n",
    "data['date'] = pd.to_datetime(data['date'], errors='coerce', utc=True)\n",
    "\n",
    "# Sort the data by date\n",
    "data = data.sort_values('date')\n",
    "\n",
    "# Verify the changes\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  headline  sentiment\n",
      "879310                        How Treasuries and ETFs Work        0.0\n",
      "519806       Update on the Luxury Sector: 2nd Quarter 2009        0.0\n",
      "1390006      Update on the Luxury Sector: 2nd Quarter 2009        0.0\n",
      "1432                                Going Against the Herd        0.0\n",
      "67712    Charles Sizemore Radio Interview Saturday Morning        0.0\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Define a function to get sentiment polarity\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "# Apply the sentiment function to each headline\n",
    "data['sentiment'] = data['headline'].apply(get_sentiment)\n",
    "\n",
    "# Check the first few rows to confirm the sentiment column has been added\n",
    "print(data[['headline', 'sentiment']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Aggregate Daily Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       date  average_sentiment\n",
      "0 2009-02-14 00:00:00+00:00           0.000000\n",
      "1 2009-04-27 00:00:00+00:00           0.000000\n",
      "2 2009-04-29 00:00:00+00:00           0.000000\n",
      "3 2009-05-22 00:00:00+00:00           0.000000\n",
      "4 2009-05-27 00:00:00+00:00           0.234091\n"
     ]
    }
   ],
   "source": [
    "# Group by 'date' and calculate the mean sentiment score\n",
    "daily_sentiment = data.groupby('date')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "daily_sentiment.columns = ['date', 'average_sentiment']\n",
    "\n",
    "# Check the results\n",
    "print(daily_sentiment.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calculate Daily Stock Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock',\n",
      "       'sentiment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             date  stock  stock_returns\n",
      "879310  2009-02-14 00:00:00+00:00    NaN            NaN\n",
      "519806  2009-04-27 00:00:00+00:00    NaN            NaN\n",
      "1390006 2009-04-27 00:00:00+00:00    NaN            NaN\n",
      "1432    2009-04-29 00:00:00+00:00    NaN            NaN\n",
      "67712   2009-05-22 00:00:00+00:00    NaN            NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h5/cqk4jd793hzd58k1ssq6mkd40000gn/T/ipykernel_7595/435945514.py:7: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  data['stock_returns'] = data['stock'].pct_change() * 100\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'stock' column is in numeric format (in case it's stored as strings)\n",
    "data['stock'] = pd.to_numeric(data['stock'], errors='coerce')\n",
    "\n",
    "# Check if the 'stock' column exists\n",
    "if 'stock' in data.columns:\n",
    "    # Calculate daily stock returns as percentage change\n",
    "    data['stock_returns'] = data['stock'].pct_change() * 100\n",
    "else:\n",
    "    print(\"Stock column not found.\")\n",
    "    \n",
    "# Check the first few rows to confirm the stock returns are calculated\n",
    "print(data[['date', 'stock', 'stock_returns']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align Sentiment Data with Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                           headline  \\\n",
      "0      883755                       How Treasuries and ETFs Work   \n",
      "1      522587      Update on the Luxury Sector: 2nd Quarter 2009   \n",
      "2     1396488      Update on the Luxury Sector: 2nd Quarter 2009   \n",
      "3        1834                             Going Against the Herd   \n",
      "4       68387  Charles Sizemore Radio Interview Saturday Morning   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://www.benzinga.com/28044/how-treasuries-...   \n",
      "1  https://www.benzinga.com/charles-lewis-sizemor...   \n",
      "2  https://www.benzinga.com/charles-lewis-sizemor...   \n",
      "3  https://www.benzinga.com/charles-lewis-sizemor...   \n",
      "4  https://www.benzinga.com/11218/charles-sizemor...   \n",
      "\n",
      "                    publisher                      date  stock  sentiment  \\\n",
      "0                Paco Ahlgren 2009-02-14 00:00:00+00:00    NaN        0.0   \n",
      "1  Charles Lewis Sizemore CFA 2009-04-27 00:00:00+00:00    NaN        0.0   \n",
      "2  Charles Lewis Sizemore CFA 2009-04-27 00:00:00+00:00    NaN        0.0   \n",
      "3  Charles Lewis Sizemore CFA 2009-04-29 00:00:00+00:00    NaN        0.0   \n",
      "4  Charles Lewis Sizemore CFA 2009-05-22 00:00:00+00:00    NaN        0.0   \n",
      "\n",
      "   stock_returns  average_sentiment  \n",
      "0            NaN                0.0  \n",
      "1            NaN                0.0  \n",
      "2            NaN                0.0  \n",
      "3            NaN                0.0  \n",
      "4            NaN                0.0  \n"
     ]
    }
   ],
   "source": [
    "# Merge sentiment and stock data on 'date'\n",
    "merged_data = pd.merge(data, daily_sentiment, on='date')\n",
    "\n",
    "# Inspect the merged data\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Column names in the dataset: Index(['Unnamed: 0', 'headline', 'url', 'publisher', 'date', 'stock'], dtype='object')\n",
      "Missing necessary columns: 'stock', 'sentiment', or 'date'. Please check your data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # Load the data (adjust file path as necessary)\n",
    "    data = pd.read_csv('../data/raw_analyst_ratings.csv')  # Replace with your actual file path\n",
    "    print(\"Data loaded successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Print the column names to inspect them\n",
    "print(\"Column names in the dataset:\", data.columns)\n",
    "\n",
    "# Check if the necessary columns exist\n",
    "if 'stock' in data.columns and 'sentiment' in data.columns and 'date' in data.columns:\n",
    "    # Step 1: Calculate daily returns\n",
    "    data['Daily_Return'] = data['stock'].pct_change() * 100\n",
    "\n",
    "    # Step 2: Ensure 'date' is in datetime format\n",
    "    data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
    "\n",
    "    # Step 3: Group by 'date' and calculate average sentiment for each day\n",
    "    daily_sentiment = data.groupby('date')['sentiment'].mean().reset_index()\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    daily_sentiment.columns = ['date', 'Average_Sentiment']\n",
    "\n",
    "    # Step 4: Merge sentiment and stock returns data on 'date'\n",
    "    merged_data = pd.merge(data, daily_sentiment, on='date')\n",
    "\n",
    "    # Step 5: Calculate Pearson correlation\n",
    "    correlation = merged_data['Daily_Return'].corr(merged_data['Average_Sentiment'])\n",
    "\n",
    "    # Step 6: Print the correlation result\n",
    "    print(f\"The correlation between sentiment and stock returns is: {correlation}\")\n",
    "else:\n",
    "    print(\"Missing necessary columns: 'stock', 'sentiment', or 'date'. Please check your data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
